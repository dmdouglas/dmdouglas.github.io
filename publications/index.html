<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Publications | David M. Douglas </title> <meta name="author" content="David M. Douglas"> <meta name="description" content="publications by categories in reversed chronological order. Generated by jekyll-scholar."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%93%9A&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://dmdouglas.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">David</span> M. Douglas </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description">publications by categories in reversed chronological order. Generated by jekyll-scholar.</p> </header> <article> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#b31b1b"> <a href="https://arxiv.org" rel="external nofollow noopener" target="_blank">arXiv</a> </abbr> </div> <div id="sanderson2024resolving" class="col-sm-8"> <div class="title">Resolving Ethics Trade-offs in Implementing Responsible AI</div> <div class="author"> Conrad Sanderson, Emma Schleiger, <em>David Douglas</em>, Petra Kuhnert, and Qinghua Lu </div> <div class="periodical"> 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2401.08103" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-pmid="" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>While the operationalisation of high-level AI ethics principles into practical AI/ML systems has made progress, there is still a theory-practice gap in managing tensions between the underlying AI ethics aspects. We cover five approaches for addressing the tensions via trade-offs, ranging from rudimentary to complex. The approaches differ in the types of considered context, scope, methods for measuring contexts, and degree of justification. None of the approaches is likely to be appropriate for all organisations, systems, or applications. To address this, we propose a framework which consists of: (i) proactive identification of tensions, (ii) prioritisation and weighting of ethics aspects, (iii) justification and documentation of trade-off decisions. The proposed framework aims to facilitate the implementation of well-rounded AI/ML systems that are appropriate for potential regulatory requirements. </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#688000"> <a href="https://www.sciencedirect.com/journal/environmental-impact-assessment-review" rel="external nofollow noopener" target="_blank">EIAR</a> </abbr> </div> <div id="malakar2024just" class="col-sm-8"> <div class="title">Just Trade-Offs in a Net-Zero Transition and Social Impact Assessment</div> <div class="author"> Yuwan Malakar, Andrea Walton, Luk J.M. Peeters, <em>David M. Douglas</em>, and Dan O’Sullivan </div> <div class="periodical"> <em>Environmental Impact Assessment Review</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.sciencedirect.com/science/article/pii/S0195925524000933" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1016/j.eiar.2024.107506" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Countries around the world are prioritising net zero emissions to meet their Paris Agreement goals. The demand for social impact assessment (SIA) is likely to grow as this transition will require investments in decarbonisation projects with speed and at scale. There will be winners and losers of these projects because not everyone benefits the same; and hence, trade-offs are inevitable. SIAs, therefore, should focus on understanding how the risks and benefits will be distributed among and within stakeholders and sectors and enable the identification of trade-offs that are just and fair. In this study, we used a hypothetical case of large-scale hydrogen production in regional Australia and engaged with multi-disciplinary experts to identify justice issues in transitioning to such an industry. Using Rawlsian theory of justice as fairness, we identified several tensions between different groups (national, regional, local, inter and intra-communities) and sectors (environmental and economic) concerning the establishment of a hydrogen industry. These stakeholders and sectors will be disproportionately affected by this establishment. We argue that Rawlsian principles of justice would enable the practice of SIA to identify justice trade-offs. Further, we conceptualise that a systems approach will be critical to facilitate a wider participation, and an agile process for achieving just trade-offs in SIA.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#e7600e"> <a href="https://link.springer.com/journal/43681" rel="external nofollow noopener" target="_blank">AI Ethics</a> </abbr> </div> <div id="douglas2024ethical" class="col-sm-8"> <div class="title">Ethical Risk for AI</div> <div class="author"> <em>David M. Douglas</em>, Justine Lacey, and David Howard </div> <div class="periodical"> <em>AI &amp; Ethics</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/douglas-et-al_2024_ethical-risk-for-ai.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://doi.org/10.1007/s43681-024-00549-9" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/s43681-024-00549-9" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>The term ’ethical risk’ often appears in discussions about the responsible development and deployment of artificial intelligence (AI). However, ethical risk remains inconsistently defined in this context, obscuring what distinguishes it from other forms of risk, such as social, reputational or legal risk, for example. In this paper we present a definition of ethical risk for AI as being any risk associated with an AI that may cause stakeholders to fail one or more of their ethical responsibilities towards other stakeholders. To support our definition, we describe how stakeholders have role responsibilities that follow from their relationship with the AI, and that these responsibilities are towards other stakeholders associated with the AI. We discuss how stakeholders may differ in their ability to make decisions about an AI, their exposure to risk, and whether they or others may benefit from these risks. Stakeholders without the ability to make decisions about the risks associated with an AI and how it is used are dependent on other stakeholders with this ability. This relationship places those who depend on decision-making stakeholders at ethical risk of being dominated by them. The decision-making stakeholder is ethically responsible for the risks their decisions about the AI impose on those affected by them. We illustrate our account of ethical risk for AI with two examples: AI-designed attachments for surgical robots that are optimised for treating specific patients, and self-driving ’robotaxis’ that carry passengers on public roads.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#e7600e"> <a href="https://link.springer.com/journal/43681" rel="external nofollow noopener" target="_blank">AI Ethics</a> </abbr> </div> <div id="douglas_ethical_2023" class="col-sm-8"> <div class="title">Ethical risks of AI-designed products: bespoke surgical tools as a case study</div> <div class="author"> <em>David M. Douglas</em>, Justine Lacey, and David Howard </div> <div class="periodical"> <em>AI and Ethics</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/douglas-et-al_2023_ethical-risks-of-ai%E2%80%93designed-products.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://link.springer.com/article/10.1007/s43681-022-00219-8" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/s43681-022-00219-8" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>An emerging use of machine learning (ML) is creating products optimised using computational design for individual users and produced using 3D printing. One potential application is bespoke surgical tools optimised for specific patients. While optimised tool designs benefit patients and surgeons, there is the risk that computational design may also create unexpected designs that are unsuitable for use with potentially harmful consequences. We interviewed potential stakeholders to identify both established and unique technical risks associated with the use of computational design for surgical tool design and applied ethical risk analysis (eRA) to identify how stakeholders might be exposed to ethical risk within this process. The main findings of this research are twofold. First, distinguishing between unique and established risks for new medical technologies helps identify where existing methods of risk mitigation may be applicable to a surgical innovation, and where new means of mitigating risks may be needed. Second, the value of distinguishing between technical and ethical risks in such a system is that it identifies the key responsibilities for managing these risks and allows for any potential interdependencies between stakeholders in managing these risks to be made explicit. The approach demonstrated in this paper may be applied to understanding the implications of new AI and ML applications in healthcare and other high consequence domains.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00a1b7"> <a href="https://technologyandsociety.org/transactions/" rel="external nofollow noopener" target="_blank">IEEE-TTS</a> </abbr> </div> <div id="sanderson_ai_2023" class="col-sm-8"> <div class="title">AI Ethics Principles in Practice: Perspectives of Designers and Developers</div> <div class="author"> Conrad Sanderson, <em>David Douglas</em>, Qinghua Lu, Emma Schleiger, Jon Whittle, Justine Lacey, Glenn Newnham, Stefan Hajkowicz, Cathy Robinson, and David Hansen </div> <div class="periodical"> <em>IEEE Transactions on Technology and Society</em>, Jun 2023 </div> <div class="periodical"> Conference Name: IEEE Transactions on Technology and Society </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/10071542" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/TTS.2023.3257303" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>As consensus across the various published AI ethics principles is approached, a gap remains between high-level principles and practical techniques that can be readily adopted to design and develop responsible AI systems. We examine the practices and experiences of researchers and engineers from Australia’s national scientific research agency (CSIRO), who are involved in designing and developing AI systems for many application areas. Semi-structured interviews were used to examine how the practices of the participants relate to and align with a set of high-level AI ethics principles proposed by the Australian Government. The principles comprise: (1) privacy protection and security, (2) reliability and safety, (3) transparency and explainability, (4) fairness, (5) contestability, (6) accountability, (7) human-centred values, (8) human, social and environmental well-being. Discussions on the gained insights from the interviews include various tensions and trade-offs between the principles, and provide suggestions for implementing each high-level principle. We also present suggestions aiming to enhance associated support mechanisms.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#14303e"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=9670" rel="external nofollow noopener" target="_blank">IEEE Intell. Syst.</a> </abbr> </div> <div id="duenser_who_2023" class="col-sm-8"> <div class="title">Who to Trust, How and Why: Untangling AI Ethics Principles, Trustworthiness and Trust</div> <div class="author"> Andreas Duenser, and <em>David M. Douglas</em> </div> <div class="periodical"> <em>IEEE Intelligent Systems</em>, Jun 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/10273868" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/MIS.2023.3322586" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>We present an overview of the literature on trust in AI and AI trustworthiness and argue for the need to distinguish these concepts more clearly and to gather more empirically evidence on what contributes to people’s trusting behaviours. We discuss that trust in AI involves not only reliance on the system itself, but also trust in the developers of the AI system. AI ethics principles such as explainability and transparency are often assumed to promote user trust, but empirical evidence of how such features actually affect how users perceive the system’s trustworthiness is not as abundance or not that clear. AI systems should be recognised as socio-technical systems, where the people involved in designing, developing, deploying, and using the system are as important as the system for determining whether it is trustworthy. Without recognising these nuances, ’trust in AI’ and ’trustworthy AI’ risk becoming nebulous terms for any desirable feature for AI systems.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#b31b1b"> <a href="https://arxiv.org" rel="external nofollow noopener" target="_blank">arXiv</a> </abbr> </div> <div id="sanderson2023implementing" class="col-sm-8"> <div class="title">Implementing Responsible AI: Tensions and Trade-Offs Between Ethics Aspects</div> <div class="author"> Conrad Sanderson, <em>David Douglas</em>, and Qinghua Lu </div> <div class="periodical"> <em>arXiv preprint arXiv:2304.08275</em>, Jun 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2304.08275" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/IJCNN54540.2023.10191274" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Many sets of ethics principles for responsible AI have been proposed to allay concerns about misuse and abuse of AI/ML systems. The underlying aspects of such sets of principles include privacy, accuracy, fairness, robustness, explainability, and transparency. However, there are potential tensions between these aspects that pose difficulties for AI/ML developers seeking to follow these principles. For example, increasing the accuracy of an AI/ML system may reduce its explainability. As part of the ongoing effort to operationalise the principles into practice, in this work we compile and discuss a catalogue of 10 notable tensions, trade-offs and other interactions between the underlying aspects. We primarily focus on two-sided interactions, drawing on support spread across a diverse literature. This catalogue can be helpful in raising awareness of the possible interactions between aspects of ethics principles, as well as facilitating well-supported judgements by the designers and developers of AI/ML systems.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#b31b1b"> <a href="https://arxiv.org" rel="external nofollow noopener" target="_blank">arXiv</a> </abbr> </div> <div id="sanderson_towards_2022" class="col-sm-8"> <div class="title">Towards Operationalising Responsible AI: An Empirical Study</div> <div class="author"> Conrad Sanderson, Qinghua Lu, <em>David Douglas</em>, Xiwei Xu, Liming Zhu, and Jon Whittle </div> <div class="periodical"> <em>arXiv:2205.04358 [cs]</em>, May 2022 </div> <div class="periodical"> arXiv: 2205.04358 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2205.04358" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/BigData55660.2022.10021121" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>While artificial intelligence (AI) has great potential to transform many industries, there are concerns about its ability to make decisions in a responsible way. Many AI ethics guidelines and principles have been recently proposed by governments and various organisations, covering areas such as privacy, accountability, safety, reliability, transparency, explainability, contestability, and fairness. However, such principles are typically high-level and do not provide tangible guidance on how to design and develop responsible AI systems. To address this shortcoming, we present an empirical study involving interviews with 21 scientists and engineers, designed to gain insight into practitioners’ perceptions of AI ethics principles, their possible implementation, and the trade-offs between the principles. The salient findings cover four aspects of AI system development: (i) overall development process, (ii) requirements engineering, (iii) design and implementation, (iv) deployment and operation.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#b9babc"> <a href="https://link.springer.com/journal/10676" rel="external nofollow noopener" target="_blank">Ethics Inf. Technol.</a> </abbr> </div> <div id="douglas_ethical_2022" class="col-sm-8"> <div class="title">Ethical responsibility and computational design: bespoke surgical tools as an instructive case study</div> <div class="author"> <em>David M. Douglas</em>, Justine Lacey, and David Howard </div> <div class="periodical"> <em>Ethics and Information Technology</em>, Feb 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/douglas-et-al_2022_ethical-responsibility-and-computational-design.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://link.springer.com/article/10.1007/s10676-022-09641-2" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/s10676-022-09641-2" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Computational design uses artificial intelligence (AI) to optimise designs towards user-determined goals. When combined with 3D printing, it is possible to develop and construct physical products in a wide range of geometries and materials and encapsulating a range of functionality, with minimal input from human designers. One potential application is the development of bespoke surgical tools, whereby computational design optimises a tool’s morphology for a specific patient’s anatomy and the requirements of the surgical procedure to improve surgical outcomes. This emerging application of AI and 3D printing provides an opportunity to examine whether new technologies affect the ethical responsibilities of those operating in high-consequence domains such as healthcare. This research draws on stakeholder interviews to identify how a range of different professions involved in the design, production, and adoption of computationally designed surgical tools, identify and attribute responsibility within the different stages of a computationally designed tool’s development and deployment. Those interviewed included surgeons and radiologists, fabricators experienced with 3D printing, computational designers, healthcare regulators, bioethicists, and patient advocates. Based on our findings, we identify additional responsibilities that surround the process of creating and using these tools. Additionally, the responsibilities of most professional stakeholders are not limited to individual stages of the tool design and deployment process, and the close collaboration between stakeholders at various stages of the process suggests that collective ethical responsibility may be appropriate in these cases. The role responsibilities of the stakeholders involved in developing the process to create computationally designed tools also change as the technology moves from research and development (R&amp;D) to approved use.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="sanderson_towards_2023" class="col-sm-8"> <div class="title">Towards Implementing Responsible AI</div> <div class="author"> Conrad Sanderson, Qinghua Lu, <em>David Douglas</em>, Xiwei Xu, Liming Zhu, and Jon Whittle </div> <div class="periodical"> <em>In 2022 IEEE International Conference on Big Data (Big Data)</em>, Dec 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/10021121" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/BigData55660.2022.10021121" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>As the deployment of artificial intelligence (AI) is changing many fields and industries, there are concerns about AI systems making decisions and recommendations without adequately considering various ethical aspects, such as accountability, reliability, transparency, explainability, contestability, privacy, and fairness. While many sets of AI ethics principles have been recently proposed that acknowledge these concerns, such principles are high-level and do not provide tangible advice on how to develop ethical and responsible AI systems. To gain insight on the possible implementation of the principles, we conducted an empirical investigation involving semi-structured interviews with a cohort of AI practitioners. The salient findings cover four aspects of AI system design and development, adapting processes used in software engineering: (i) high-level view, (ii) requirements engineering, (iii) design and implementation, (iv) deployment and operation.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#b31b1b"> <a href="https://arxiv.org" rel="external nofollow noopener" target="_blank">arXiv</a> </abbr> </div> <div id="lu2022software" class="col-sm-8"> <div class="title">Software engineering for responsible AI: An empirical study and operationalised patterns</div> <div class="author"> Qinghua Lu, Liming Zhu, Xiwei Xu, Jon Whittle, <em>David Douglas</em>, and Conrad Sanderson </div> <div class="periodical"> <em>In Proceedings of the 44th International Conference on Software Engineering: Software Engineering in Practice</em>, Dec 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/ICSE-SEIP55303.2022.9793864" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>AI ethics principles and guidelines are typically high-level and do not provide concrete guidance on how to develop responsible AI systems. To address this shortcoming, we perform an empirical study involving interviews with 21 scientists and engineers to understand the practitioners’ views on AI ethics principles and their implementation. Our major findings are: (1) the current practice is often a done-once-and-forget type of ethical risk assessment at a particular development step, which is not sufficient for highly uncertain and continual learning AI systems; (2) ethical requirements are either omitted or mostly stated as high-level objectives, and not specified explicitly in verifiable way as system outputs or outcomes; (3) although ethical requirements have the characteristics of cross-cutting quality and non-functional requirements amenable to architecture and design analysis, system-level architecture and design are under-explored; (4) there is a strong desire for continuously monitoring and validating AI systems post deployment for ethical requirements but current operation practices provide limited guidance. To address these findings, we suggest a preliminary list of patterns to provide operationalised guidance for developing responsible AI systems.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#e7600e"> <a href="https://link.springer.com/journal/43681" rel="external nofollow noopener" target="_blank">AI Ethics</a> </abbr> </div> <div id="douglas_moral_2021" class="col-sm-8"> <div class="title">Moral responsibility for computationally designed products</div> <div class="author"> <em>David M. Douglas</em>, David Howard, and Justine Lacey </div> <div class="periodical"> <em>AI and Ethics</em>, Dec 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/douglas-et-al_2021_moral-responsibility-for-computationally-designed-products.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://link.springer.com/article/10.1007/s43681-020-00034-z" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/s43681-020-00034-z" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Computational design systems (such as those using evolutionary algorithms) can create designs for a variety of physical products. Introducing these systems into the design process risks creating a ‘responsibility gap’ for flaws in the products they are used to create, as human designers may no longer believe that they are wholly responsible for them. We respond to this problem by distinguishing between causal responsibility and capacity responsibility (the ability to be morally responsible for actions) for creating product designs to argue that while the computational design systems and human designers are both casually responsible for creating product designs, the human designers who use these systems and the developers who create them have capacity responsibility for such designs. We show that there is no responsibility gap for products designed using computational design systems by comparing different accounts of moral responsibility for robots and AI (instrumentalism, machine ethics, and hybrid responsibility). We argue that all three of these accounts of moral responsibility for AI systems support the conclusion that the product designers who use computational design systems and the developers of these systems are morally responsible for any flaws or faults in the products designed by these systems. We conclude by showing how the responsibilities of accountability and blameworthiness should be attributed between the product designers, the developers of the computational design systems.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="douglas_doxing_2020" class="col-sm-8"> <div class="title">Doxing as Audience Vigilantism against Hate Speech</div> <div class="author"> <em>David M. Douglas</em> </div> <div class="periodical"> <em>In Introducing Vigilant Audiences</em>, Dec 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.openbookpublishers.com/books/10.11647/obp.0200/chapters/10.11647/obp.0200.10" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Doxing is the public release of personally identifiable information, and may be used as a tool for activism by removing the anonymity of individuals whose actions or stated beliefs harm others or undermine social cohesion. In this chapter I describe how doxing that deanomynises proponents of hate speech is a form of audience vigilantism. I argue that it is a defensible means of combating hate speech if it has the purpose of beginning a process of deradicalizing the identified individuals through reintegrative shaming. Such doxing must be motivated by a legitimate social need (in that they can be justified using premises and evidence acceptable to all in society),and must remain within socially tolerable bounds (in that it does not lead to physical harm, it is not indiscriminate, and is in response to injustices that are in principle recognisable to those who are not affected by it). I refer to several instances of doxing relating to proponents of hate speech to illustrate my argument and to demonstrate the importance of the legitimate social need and socially tolerable bounds criteria.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="kinkead_network_2020" class="col-sm-8"> <div class="title">The Network and the Demos: Big Data and the Epistemic Justifications of Democracy</div> <div class="author"> Dave Kinkead, and <em>David M. Douglas</em> </div> <div class="periodical"> <em>In Big Data and Democracy</em>, Dec 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://academic.oup.com/edinburgh-scholarship-online/book/37474/chapter-abstract/331652108?redirectedFrom=fulltext" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.3366/edinburgh/9781474463522.003.0009" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>In this chapter, Kinkead and Douglas draw on the history of democracies to see how big data and its use with social media sites introduces new challenges to the contemporary marketplace of ideas. They note that traditionally one could narrowcast a tailored message with some impunity, but limited effect, while broadcasts (with larger impact) were open to examination by the public. Microtargeted political advertising now allows for the narrowcast message to be tweaked and directed on a scale never before seen.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00a9ce"> <a href="https://www.csiro.au/" rel="external nofollow noopener" target="_blank">CSIRO</a> </abbr> </div> <div id="ibarra2020machine" class="col-sm-8"> <div class="title">Machine Learning and Responsibility in Criminal Investigation</div> <div class="author"> Georgina Ibarra, <em>David Douglas</em>, and Meena Tharmarajah </div> <div class="periodical"> Dec 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://publications.csiro.au/publications/publication/PIcsiro:EP205485" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.25919/5f8dd4294a47f" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Most of the literature on using machine learning (ML) systems in criminal investigations concerns whether using these systems undermines public trust in law enforcement. A related concern is whether investigators themselves should trust these systems. But what do we really mean by ‘trust’? Many methods have been developed for promoting fairness, transparency, and accountability in the predictions made by ML systems, however a technical approach to these problems needs to be accompanied by a human centred approach to user trust. In order to address social, ethical and practical issues these systems need to present information in such a way that the people that use them can make balanced decisions on whether or not they should trust them. In this report we use the lens of user experience (UX) and social science to look at how the role responsibilities and accountability of criminal justice experts may be affected by the use of ML systems in criminal investigations. How will these systems be used by these experts and what is the effect that may have in this regulated and legislated environment? To understand this, we explore the concepts of responsibility, accountability and transparency in the context of criminal investigations in parallel to the various levels of automation and AI assistance ranging from full human control to full automation. We discuss why ML systems used in criminal investigations can be considered ‘human-in-the-loop’ forms of automation, where the systems offer decision support to users. We also explore the issues connected with calibrating trust in an ML system, describing the characteristics of automated systems that affect the ability of users to determine if their trust in a system is legitimate, and the risks of misusing, rejecting, and abusing automation by experts operating in criminal justice settings. We highlight the risks connected with using ML systems, and how these risks might affect the use of these systems in criminal justice contexts. The report summarises additional areas of responsibility across the ecosystem of machine learning systems in a criminal context including: the responsibility of law enforcement institutions to train their workforce in the skills needed to use data and insights from ML systems; the responsibility of specific departments in these organisations to examine the intended use of such systems, adjusting their internal policies accordingly and ensuring their employees are alert to how this affects their responsibility or accountability; and the responsibility of technologists to be transparent about the system’s trustworthiness, and to allow experts to accurately calibrate their trust in the system by closely observing and responding to how they interpret and use different types of predictive data in investigative processes.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff7f00"> <a href="https://www.sienna-project.eu/" rel="external nofollow noopener" target="_blank">SIENNA</a> </abbr> </div> <div id="jensen_ethical_2019" class="col-sm-8"> <div class="title">Ethical Analysis of AI and Robotics Technologies</div> <div class="author"> Philip Jensen, Philip Brey, Alice Fox, Jonne Maas, Bradley Hillas, Nils Wagner, Patrick Smith, Isaac Oluoch, Laura Lamers, Hero Gein, Anaïs Resseguier, Rowena Rodrigues, David Wright, and <em>David Douglas</em> </div> <div class="periodical"> Dec 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.sienna-project.eu/digitalAssets/801/c_801912-l_1-k_d4.4_ethical-analysis%E2%80%93ai-and-r%E2%80%93with-acknowledgements.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>This SIENNA deliverable offers a broad ethical analysis of artificial intelligence (AI) and robotics technologies. Its primary aims have been to comprehensively identify and analyse the present and potential future ethical issues in relation to: (1) the AI and robotics subfields, techniques, approaches and methods; (2) their physical technological products and procedures that are designed for practical applications; and (3) the particular uses and applications of these products and procedures. In conducting the ethical analysis, we strove to provide ample clarification, details about nuances, and contextualisation of the ethical issues that were identified, while avoiding the making of moral judgments and proposing of solutions to these issues. A secondary aim of this report has been to convey the results of SIENNA’s “country studies” of the national academic and popular media debate on the ethical issues in AI and robotics in twelve different EU and non-EU countries, highlighting the similarities and differences between these countries. While these country study results have only formed a minor contribution to the overall identification and analysis of the ethical issues in this report, they are expected to play a larger role in future SIENNA deliverables. This deliverable also provides an overview of the history and state of the art of the academic debate on ethics of AI and robot ethics, and an overview of the current institutional support of these fields.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#3395b6"> <a href="https://cacm.acm.org/" rel="external nofollow noopener" target="_blank">Comm. ACM</a> </abbr> </div> <div id="douglas_should_2019" class="col-sm-8"> <div class="title">Should researchers use data from security breaches?</div> <div class="author"> <em>David M. Douglas</em> </div> <div class="periodical"> <em>Communications of the ACM</em>, Nov 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3368091" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1145/3368091" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Evaluating the arguments for and against using digital data derived from security breaches.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#78b800"> <a href="https://delphi.lexxion.eu/" rel="external nofollow noopener" target="_blank">Delphi</a> </abbr> </div> <div id="gertz2019cyberwar" class="col-sm-8"> <div class="title">Cyberwar and Mediation Theory</div> <div class="author"> Nolen Gertz, Peter-Paul Verbeek, and <em>David M. Douglas</em> </div> <div class="periodical"> <em>Delphi - Interdisciplinary Review of Emerging Technologies</em>, Nov 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://delphi.lexxion.eu/article/delphi/2019/2/5" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Cyberwar (military operations conducted via computer networks) is often downplayed compared to traditional military operations as they are largely invisible to outside observers, difficult to convincingly attribute to a particular source and rarely cause physical damage or obvious harm. We use mediation theory to argue that cyberwar operations cause harm by undermining trust in computerised devices and networks and by disrupting the transparency of our usage of information technology in our daily lives. Cyberwar operations militarise and weaponise the civilian space of the Internet by co-opting and targeting civilian infrastructure and property. These operations (and the possibility of such operations occurring) fundamentally change users’ Internet experience by fostering fear and paranoia about otherwise unnoticed and transparent aspects of their lives, similarly to how biological and chemical weapons create fear and paranoia about breathing, eating, and physical exposure to the world. We argue that the phenomenological aspects of cyberwar operations offer a compelling justification for prohibiting cyberwar in the same manner in which biological and chemical warfare are prohibited.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2018</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#1c2340"> <a href="https://link.springer.com/journal/11948" rel="external nofollow noopener" target="_blank">Sci Eng Ethics</a> </abbr> </div> <div id="douglas_should_2018" class="col-sm-8"> <div class="title">Should Internet Researchers Use Ill-Gotten Information?</div> <div class="author"> <em>David M. Douglas</em> </div> <div class="periodical"> <em>Science and Engineering Ethics</em>, Aug 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://link.springer.com/article/10.1007/s11948-017-9935-x" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/s11948-017-9935-x" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>This paper describes how the ethical problems raised by scientific data obtained through harmful and immoral conduct (which, following Stan Godlovitch, is called ill-gotten information) may also emerge in cases where data is collected from the Internet. It describes the major arguments for and against using ill-gotten information in research, and shows how they may be applied to research that either collects information about the Internet itself or which uses data from questionable or unknown sources on the Internet. Three examples (the Internet Census 2012, the PharmaLeaks study, and research into keylogger dropzones) demonstrate how researchers address the ethical issues raised by the sources of data that they use and how the existing arguments concerning the use of ill-gotten information apply to Internet research. The problems faced by researchers who collect or use data from the Internet are shown to be the same problems faced by researchers in other fields who may obtain or use ill-gotten information.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="douglas2018personal" class="col-sm-8"> <div class="title">Personal Information, Identification Information, and Identity Knowledge</div> <div class="author"> David M Douglas </div> <div class="periodical"> <em>UniSA Student Law Review</em>, Aug 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ojs.unisa.edu.au/index.php/uslr/article/view/1491" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>This commentary responds to the primary article by Åste Corbridge in this volume entitled ‘Responding to Doxing in Australia: Towards a Right to Informational Self-Determination?’. It discusses the way that concepts of ‘personal information’ and ‘identification information’ from the Privacy Act 1988 (Cth) correspond with the seven crucial types of identity knowledge identified by Gary T. Marx and argues that these statutory definitions should be expanded to offer better protection to victims of doxing in Australia.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#f7a600"> <a href="https://satoriproject.eu/" rel="external nofollow noopener" target="_blank">SATORI</a> </abbr> </div> <div id="jensen_reasoned_2017" class="col-sm-8"> <div class="title">A Reasoned Proposal for Shared Approaches to Ethics Assessment in the European Context</div> <div class="author"> Philip Jensen, Wessel Reijers, <em>David Douglas</em>, Faridun Sattarov, Agata Gurzawska, Alexandra Kapeller, Philip Brey, Rok Benčin, Zuzanna Warso, and Robert Braun </div> <div class="periodical"> May 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://satoriproject.eu/media/D4.1_Proposal_Ethics_Assessment_Framework.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>This report presents a comprehensive proposal for a common ethics assessment framework for research and innovation (R&amp;I) in the European Union member states. It details recommendations for good practices for ethics assessment, which includes the development of ethics assessment units and the protocols of these units. More specifically, the report presents a general toolkit for ethics assessment of R&amp;I, as well as specialised tools and toolkits for specific types of organizations that deal with ethics assessment, and for different scientific fields.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#f7a600"> <a href="https://satoriproject.eu/" rel="external nofollow noopener" target="_blank">SATORI</a> </abbr> </div> <div id="leinonen_roadmap_2017" class="col-sm-8"> <div class="title">Roadmap towards Adoption of a Fully Developed Ethics Assessment Framework</div> <div class="author"> Anna Leinonen, Raija Koivisto, Anu Tuominen, <em>David Douglas</em>, Agata Gurzawska, Philip Jansen, Alexandra Kapeller, and Philip Brey </div> <div class="periodical"> May 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://satoriproject.eu/media/D4.3_SATORIRoadmap.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>The aim of the SATORI roadmap process was to work out how the SATORI ethics assessment framework can be implemented in practice. The timespan of the roadmap was set at 10 years. To begin, a vision of a future in which the SATORI framework is implemented was formulated. Theories about the implementation of new social practices were subsequently studied, and a model for the implementation of the SATORI framework was constructed. This model was then used as the basis for identifying the steps (or outcomes) that need to be taken in order to realise the vision. Finally, these steps were fleshed out by listing recommendations and associated actions that need to be taken by various stakeholder groups that are involved in ethics assessment of research and innovation.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#f7a600"> <a href="https://satoriproject.eu/" rel="external nofollow noopener" target="_blank">SATORI</a> </abbr> </div> <div id="callies_outline_2017" class="col-sm-8"> <div class="title">Outline of an Ethics Assessment Framework</div> <div class="author"> Ingrid Callies, Philip Jansen, Wessel Reijers, <em>David Douglas</em>, Agata Gurzawska, Alexandra Kapeller, Philip Brey, Rok Benčin, and Zuzanna Warso </div> <div class="periodical"> May 2017 </div> <div class="periodical"> </div> <div class="links"> <a href="http://satoriproject.eu/media/D4.2_Outline_of_an_Ethics_Assessment_Framework.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#78a2d7"> <a href="https://www.emerald.com/insight/publication/issn/1477-996X" rel="external nofollow noopener" target="_blank">JICES</a> </abbr> </div> <div id="douglas_dual-use_2017" class="col-sm-8"> <div class="title">Dual-Use or No-Use? The Ethics of Booters and DDoS-for-Hire</div> <div class="author"> <em>David M. Douglas</em>, José Jair Santanna, Ricardo de O. Schmidt, Lisandro Z. Granville, and Aiko Pras </div> <div class="periodical"> <em>Journal of Information, Communication and Ethics in Society</em>, May 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.emerald.com/insight/content/doi/10.1108/JICES-09-2016-0033/full/html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1108/JICES-09-2016-0033" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Purpose: This paper examines whether there are morally defensible reasons for using or operating websites (called ‘booters’) that offer Distributed Denial-of-Service (DDoS) attacks on a specified target to users for a price. Booters have been linked to some of the most powerful DDoS attacks in recent years. Design/methodology/approach: The authors identify the various parties associated with booter websites and the means through which booters operate. Then the authors present and evaluate the two arguments that they claim may be used to justify operating and using booters: that they are a useful tool for testing the ability of networks and servers to handle heavy traffic, and that they may be used to perform DDoS attacks as a form of civil disobedience on the Internet. Findings: The authors argue that the characteristics of existing booters disqualify them from being morally justified as network stress testing tools or as a means of performing civil disobedience. The use of botnets that include systems without the permission of their owners undermines the legitimacy of both justifications. While a booter that does not use any third-party systems without permission might in principle be justified under certain conditions, the authors argue that it is unlikely that any existing booters meet these requirements. Practical implications: Law enforcement agencies may use the arguments presented here to justify shutting down the operation of booters, and so reduce the number of DDoS attacks on the Internet. Originality/value: The value of this work is in critically examining the potential justifications for using and operating booter websites and in further exploring the ethical aspects of using DDoS attacks as a form of civil disobedience.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#b9babc"> <a href="https://link.springer.com/journal/10676" rel="external nofollow noopener" target="_blank">Ethics Inf. Technol.</a> </abbr> </div> <div id="douglas_doxing_2016" class="col-sm-8"> <div class="title">Doxing: A Conceptual Analysis</div> <div class="author"> <em>David M. Douglas</em> </div> <div class="periodical"> <em>Ethics and Information Technology</em>, Sep 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/douglas_2016_doxing.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="http://link.springer.com/article/10.1007/s10676-016-9406-0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/s10676-016-9406-0" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Doxing is the intentional public release onto the Internet of personal information about an individual by a third party, often with the intent to humiliate, threaten, intimidate, or punish the identified individual. In this paper I present a conceptual analysis of the practice of doxing and how it differs from other forms of privacy violation. I distinguish between three types of doxing: deanonymizing doxing, where personal information establishing the identity of a formerly anonymous individual is released; targeting doxing, that discloses personal information that reveals specific details of an individual’s circumstances that are usually private, obscure, or obfuscated; and delegitimizing doxing, which reveals intimate personal information that damages the credibility of that individual. I also describe how doxing differs from blackmail and defamation. I argue that doxing may be justified in cases where it reveals wrongdoing (such as deception), but only if the information released is necessary to reveal that such wrongdoing has occurred and if it is in the public interest to reveal such wrongdoing. Revealing additional information, such as that which allows an individual to be targeted for harassment and intimidation, is unjustified. I illustrate my discussion with the examples of the alleged identification of the creator of Bitcoin, Satoshi Nakamoto, by Newsweek magazine, the identification of the notorious Reddit user Violentacrez by the blog Gawker, and the harassment of game developer Zoe Quinn in the ‘GamerGate’ Internet campaign.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#f7a600"> <a href="https://satoriproject.eu/" rel="external nofollow noopener" target="_blank">SATORI</a> </abbr> </div> <div id="brey_models_2016" class="col-sm-8"> <div class="title">Models for Ethics Assessment and Guidance in Higher Education</div> <div class="author"> Philip Brey, <em>David Douglas</em>, Alexandra Kapeller, Rok Benčin, Daniela Ovadia, and Doris Wolfslehner </div> <div class="periodical"> Sep 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://satoriproject.eu/media/D4.1_Annex_5_Universities.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>This report will investigate best practices for developing ethics assessment and guidance in universities, through research ethics committees (RECs), institutional policies, scientific integrity boards, teaching and training, and other means. The objective is to identify different means by which universities may promote and regulate consideration of ethical aspects of research and innovation within their institutions, and to make recommendations on the means that are most adequate and the ways in which they may be implemented. The report subsequently considers goals for ethics at universities, pathways for advancing ethics at universities, ethics codes and protocols, scientific integrity boards and codes, ethics assessment and research ethics committees, and ethics teaching and training. It ends with a summary of the recommendations of earlier sections.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2015</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#f7a600"> <a href="https://satoriproject.eu/" rel="external nofollow noopener" target="_blank">SATORI</a> </abbr> </div> <div id="koivisto_principles_2015" class="col-sm-8"> <div class="title">Principles and Approaches in Ethics Assessment: Ethics and Risk</div> <div class="author"> Raija Koivisto, and <em>David Douglas</em> </div> <div class="periodical"> Jun 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://satoriproject.eu/media/1.h-Ethics-and-Risk1.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>This report aims to study and discuss the ethical aspects of risk assessment and management, and how risk plays a role in the ethical assessment of research. It introduces the central concepts – risk and ethics – and examines the different phases of the risk management process from the ethical point of view. It also describes the ethical principles used to determine whether the risks of conducting research are acceptable. The increasing complexity of systems, products and services due to new technological and social developments is making risk assessment and management more challenging and emphasizes the need to consider ethical issues systematically in the risk assessment process.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#f7a600"> <a href="https://satoriproject.eu/" rel="external nofollow noopener" target="_blank">SATORI</a> </abbr> </div> <div id="ming_ethics_2015" class="col-sm-8"> <div class="title">Ethics Assessment in Different Countries: China</div> <div class="author"> Xin Ming, <em>David Douglas</em>, Agata Gurzawska, and Philip Brey </div> <div class="periodical"> Jun 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://satoriproject.eu/media/4.b-Country-report-China.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>The aim of this report is to analyse the existing structures and agents for the ethical assessment of research and innovation in China, both for the public and the private sector. The report will analyse how the national government has put into place organisational structures, laws, policies and procedures for ethical assessment, how both publicly funded and private research and innovation systems address ethical issues in research and innovation, and how ethical assessment plays a role in the activities of professional groups and associations for research and innovation and of civil society organisations (CSOs).</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#f7a600"> <a href="https://satoriproject.eu/" rel="external nofollow noopener" target="_blank">SATORI</a> </abbr> </div> <div id="van_leersum_ethics_2015" class="col-sm-8"> <div class="title">Ethics Assessment in Different Fields: Medical and Life Sciences</div> <div class="author"> Karin Leersum, and <em>David Douglas</em> </div> <div class="periodical"> Jun 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://satoriproject.eu/media/2.c-Medical-Life-sciences.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>This is a report on ethics assessment of medical and life sciences. Ethics assessment concerns the question what is good and bad or right and wrong about a certain technology or practice. Such assessments help organisations determine to what extent ethical standards should influence decision making at both organisational and individual levels. The aim of this report is to cover both the academic and non-academic traditions of ethical assessment, and the institutionalisation of ethics assessment in different types of organisations, including national and international standards and legislation. This report is a part of a larger study of the SATORI project.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#f7a600"> <a href="https://satoriproject.eu/" rel="external nofollow noopener" target="_blank">SATORI</a> </abbr> </div> <div id="shelley-egan_satori_2015" class="col-sm-8"> <div class="title">SATORI Deliverable D1.1: Ethical Assessment of Research and Innovation: A Comparative Analysis of Practices and Institutions in the EU and Selected Other Countries</div> <div class="author"> Clare Shelley-Egan, Philip Brey, Rowena Rodrigues, <em>David Douglas</em>, Agata Gurzawska, Lise Bitsch, David Wright, and Kush Wadhwa </div> <div class="periodical"> Jun 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://satoriproject.eu/media/D1.1_Ethical-assessment-of-RI_a-comparative-analysis.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>This deliverable offers a detailed picture of the de facto ethics assessment landscape in the European Union and other countries with regard to approaches, practices and institutions for ethics assessment across scientific fields, different kinds of organisations that carry out assessment, and different countries. The deliverable is based on in-depth study of ethics assessment in ten countries in the European Union, and the United States (US) and China, as well as studies of particular organisations in other EU countries. This main report summarises the results of work package 1 of the SATORI project and provides a comparative analysis of ethics assessment in the scientific fields, organisations and countries investigated.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#b9babc"> <a href="https://link.springer.com/journal/10676" rel="external nofollow noopener" target="_blank">Ethics Inf. Technol.</a> </abbr> </div> <div id="douglas_towards_2015" class="col-sm-8"> <div class="title">Towards a Just and Fair Internet: Applying Rawls’ Principles of Justice to Internet Regulation</div> <div class="author"> <em>David M. Douglas</em> </div> <div class="periodical"> <em>Ethics and Information Technology</em>, Mar 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/douglas_2015_towards-a-just-and-fair-internet.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/s10676-015-9361-1" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>I suggest that the social justice issues raised by Internet regulation be exposed and examined by using a methodology adapted from that described by John Rawls in A Theory of Justice. Rawls’ theory uses the hypothetical scenario of people deliberating about the justice of social institutions from the ‘original position’ as a method of removing bias in decision-making about justice. The original position imposes a ‘veil of ignorance’ that hides the particular circumstances of individuals from them so that they will not be influenced by self-interest. I adapt Rawls’ methodology by introducing an abstract description of information technology to those deliberating about justice from within the original position. This abstract description focuses on information devices that users can use to access information (and which may record information about them as well) and information networks that information devices use to communicate. The abstractness of this description prevents the particular characteristics of the Internet and the computing devices in use from influencing the decisions about the just use and regulation of information technology and networks. From this abstract position, the principles of justice that the participants accept for the rest of society will also apply to the computing devices people use to communicate, and to Internet regulation.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="maguire2015ethical" class="col-sm-8"> <div class="title">Ethical values and the global carbon integrity system</div> <div class="author"> Rowena Maguire, David M Douglas, Vesselin Popovski, and Hugh Breakey </div> <div class="periodical"> <em>In Ethical Values and the Integrity of the Climate Change Regime</em>, Mar 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.taylorfrancis.com/chapters/edit/10.4324/9781315580302-2/ethical-values-global-carbon-integrity-system-rowena-maguire-david-douglas-vesselin-popovski-hugh-breakey?context=ubx&amp;refId=8410143f-ba5b-4be0-9802-2cd8887ace6a" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>This chapter introduces the Comprehensive Integrity Framework as it applies to institutions, and has employed that framework to map the key factors and concepts at work in the global carbon integrity system, including reference to the global integrity regime and to one of its sub-institutions. It defines a number of key terms, including the Public Institutional Justification (PIJ), consistency-integrity, coherence-integrity and context-integrity. An institution has comprehensive-integrity if its activities, values and ethics, internal organization and external relations accord with its PIJ. Social values outside the institution can also impact upon the institution’s selection of its PIJ and its capacity to live up its PIJ. The integrity system is therefore constituted by the combination of the institution’s coherence-integrity and context-integrity. The framework to the global climate regime complex as a whole, framed around the UN Framework Convention on Climate Change (UNFCCC) and the framework in analysing one illustrative sub-institution nested within the UNFCCC the Clean Development Mechanism (CDM).</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2014</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#cc0000"> <a href="https://firstmonday.org/ojs/index.php/fm/index" rel="external nofollow noopener" target="_blank">First Monday</a> </abbr> </div> <div id="douglas_social_2014" class="col-sm-8"> <div class="title">The Social Goods of Information Networks: Complex Equality and Wu’s Separation Principles</div> <div class="author"> <em>David M. Douglas</em> </div> <div class="periodical"> <em>First Monday</em>, Sep 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://firstmonday.org/ojs/index.php/fm/article/view/4652" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.5210/fm.v19i9.4652" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>In his book ’The Master Switch: The Rise and Fall of Information Empires’, Tim Wu proposes a ’Separation Principle’ that the control of communication infrastructure should be separated from control over the information transmitted across it. I suggest that the Separation Principle can be further justified by appealing to Michael Walzer’s concept of complex equality. In this analysis, the integrated control of communication infrastructure and control over who can use it is unjust as the influence of the infrastructure sphere is influencing the sphere of expression. This gives a further theoretical justification for Wu’s Separation Principle and for resisting the monopolisation of information networks.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2013</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="douglas_pre-owned_2013" class="col-sm-8"> <div class="title">Pre-Owned Games</div> <div class="author"> <em>David M. Douglas</em> </div> <div class="periodical"> Oct 2013 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/douglas_2013_pre%E2%80%93owned-games.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>The market in second-hand or pre-owned games is made possible by provisions in copyright law that allow purchasers of copyrighted works to give or sell their copy to others. Pre-owned games are a contentious issue for game developers and publishers who see them as damaging to the sales and revenue generated by new games.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2012</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="douglas_making_2012" class="col-sm-8"> <div class="title">Making ICT Careers Accessible: The Value of Certification</div> <div class="author"> <em>David M. Douglas</em> </div> <div class="periodical"> <em>Information Age</em>, Aug 2012 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li></ol> <h2 class="bibliography">2011</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#1c2340"> <a href="https://link.springer.com/journal/11948" rel="external nofollow noopener" target="_blank">Sci Eng Ethics</a> </abbr> </div> <div id="douglas_social_2011" class="col-sm-8"> <div class="title">The Social Disutility of Software Ownership</div> <div class="author"> <em>David M. Douglas</em> </div> <div class="periodical"> <em>Science and Engineering Ethics</em>, Sep 2011 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://link.springer.com/article/10.1007/s11948-010-9224-4" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/s11948-010-9224-4" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Software ownership allows the owner to restrict the distribution of software and to prevent others from reading the software’s source code and building upon it. However, free software is released to users under software licenses that give them the right to read the source code, modify it, reuse it, and distribute the software to others. Proponents of free software such as Richard M. Stallman and Eben Moglen argue that the social disutility of software ownership is a sufficient justification for prohibiting it. This social disutility includes the social instability of disregarding laws and agreements covering software use and distribution, inequality of software access, and the inability to help others by sharing software with them. Here I consider these and other social disutility claims against withholding specific software rights from users, in particular, the rights to read the source code, duplicate, distribute, modify, imitate, and reuse portions of the software within new programs. I find that generally while withholding these rights from software users does cause some degree of social disutility, only the rights to duplicate, modify and imitate cannot legitimately be denied to users on this basis. The social disutility of withholding the rights to distribute the software, read its source code and reuse portions of it in new programs is insufficient to prohibit software owners from denying them to users. A compromise between the software owner and user can minimise the social disutility of withholding these particular rights from users. However, the social disutility caused by software patents is sufficient for rejecting such patents as they restrict the methods of reducing social disutility possible with other forms of software ownership.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#b9babc"> <a href="https://link.springer.com/journal/10676" rel="external nofollow noopener" target="_blank">Ethics Inf. Technol.</a> </abbr> </div> <div id="douglas_bundle_2011" class="col-sm-8"> <div class="title">A Bundle of Software Rights and Duties</div> <div class="author"> <em>David M. Douglas</em> </div> <div class="periodical"> <em>Ethics and Information Technology</em>, Sep 2011 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://link.springer.com/article/10.1007/s10676-010-9229-3" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/s10676-010-9229-3" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Like the ownership of physical property, the issues computer software ownership raises can be understood as concerns over how various rights and duties over software are shared between owners and users. The powers of software owners are defined in software licenses, the legal agreements defining what users can and cannot do with a particular program. To help clarify how these licenses permit and restrict users’ actions, here I present a conceptual framework of software rights and duties that is inspired by the terms of various proprietary, open source, and free software licenses. To clarify the relationships defined by these rights and duties, this framework distinguishes between software creators (the original developer), custodians (those who can control its use), and users (those who utilise the software). I define the various rights and duties that can be shared between these parties and how these rights and duties relate to each other. I conclude with a brief example of how this framework can be used by defining the concepts of free software and copyleft in terms of rights and duties.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#51247a"> <a href="https://espace.library.uq.edu.au/view/UQ:261538" rel="external nofollow noopener" target="_blank">UQ</a> </abbr> </div> <div id="douglas2011software" class="col-sm-8"> <div class="title">The Rights and Duties of Software Users: An Examination of the Ethics of Software Ownership</div> <div class="author"> <em>David M. Douglas</em> </div> <div class="periodical"> <em></em> Sep 2011 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://espace.library.uq.edu.au/view/UQ:261538" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Software ownership significantly affects the users of information technology as it allows owners to withhold rights from users and also impose duties upon them. This thesis evaluates this ownership by determining the rights and duties users should hold by using a conceptual framework of rights and duties over software to evaluate the major arguments for and against software ownership. I begin by describing the relevant aspects of software and the intellectual property laws covering it, and the software licenses defining the rights and duties of software users. I distinguish between three groups of people associated with any software project: creators (those who write the software), custodians (those who control the rights and duties others have over the software), and users (those who use the software). These classifications are used to define a set of rights and duties that these groups may possess over a particular program. The major categories of software ownership (such as the public domain, free software, open source, freeware, shareware, and retail software) are described in terms on this framework. I use this framework to determine the particular rights creators and custodians can justifiably withhold from users based on the three arguments most frequently given for why software creators should have greater control over the software they develop. These arguments claim that the creator’s labour in developing her software grants her an entitlement to claim ownership over it (the labour entitlement argument), that the creator deserves to own her program as a reward for developing it (the desert argument), and that granting ownership to creators is the most effective incentive for encouraging software development (the consequentialist incentive argument). I then examine the three major arguments for giving users greater control over software to determine the particular rights and duties that these arguments require users to possess. These arguments are that software ownership causes an unjustified social harm (the social disutility argument), that granting users more rights over software improves software quality (the open source argument), and that users need greater control over the software they use to protect their autonomy (the liberty argument). After evaluating these arguments, I conclude by comparing the different bundles of rights and duties each argument grants users to determine if there is any agreement between them over the particular rights and duties that should be granted to users and which rights creators and custodians can legitimately withhold from them. Finally, I compare the rights and duties that various kinds of software licenses grant users and determine whether they grant users the bundle of rights and duties that are justified by the arguments discussed.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2009</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="douglas_beneficial_2009" class="col-sm-8"> <div class="title">A Beneficial Monopoly: Jeremy Bentham on Monopolies and Patents</div> <div class="author"> <em>David M. Douglas</em> </div> <div class="periodical"> Sep 2009 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/douglas_2009_a-beneficial-monopoly.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Here I examine Jeremy Bentham’s arguments in favour of patents in light of his description of the five harms associated with monopolies. I find while these harms can be reduced by the limited duration and specific definition of patents, the existence of these harms means that a utilitarian (like Bentham) would have to support an alternative to patents if it produced the same positive results without the monopoly harms.</p> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 David M. Douglas. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: August 25, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script type="text/javascript">$(function(){$('[data-toggle="tooltip"]').tooltip()});</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"Publications",description:"publications by categories in reversed chronological order. Generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"Projects",description:"My research projects and projects I have participated in.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-teaching",title:"teaching",description:"Materials for courses you taught. Replace this text with your description.",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"nav-people",title:"people",description:"members of the lab or group",section:"Navigation",handler:()=>{window.location.href="/people/"}},{id:"post-new-paper-on-ethical-risk-for-ai",title:"New Paper on Ethical Risk for AI",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/ethical-risk-for-ai/"}},{id:"post-a-post-with-tabs",title:"a post with tabs",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/tabs/"}},{id:"post-a-post-with-typograms",title:"a post with typograms",description:"this is what included typograms code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/typograms/"}},{id:"post-a-post-that-can-be-cited",title:"a post that can be cited",description:"this is what a post that can be cited looks like",section:"Posts",handler:()=>{window.location.href="/blog/2024/post-citation/"}},{id:"post-a-post-with-pseudo-code",title:"a post with pseudo code",description:"this is what included pseudo code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/pseudocode/"}},{id:"post-new-paper-on-justice-in-energy-transformations",title:"New Paper on Justice in Energy Transformations",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/just-trade-offs/"}},{id:"post-cited-in-39-the-conversation-39-article",title:"Cited in 'The Conversation' Article",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/cited_conversation/"}},{id:"post-a-post-with-code-diff",title:"a post with code diff",description:"this is how you can display code diffs",section:"Posts",handler:()=>{window.location.href="/blog/2024/code-diff/"}},{id:"post-a-post-with-advanced-image-components",title:"a post with advanced image components",description:"this is what advanced image components could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/advanced-images/"}},{id:"post-a-post-with-vega-lite",title:"a post with vega lite",description:"this is what included vega lite code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/vega-lite/"}},{id:"post-a-post-with-geojson",title:"a post with geojson",description:"this is what included geojson code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/geojson-map/"}},{id:"post-a-post-with-echarts",title:"a post with echarts",description:"this is what included echarts code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/echarts/"}},{id:"post-a-post-with-chart-js",title:"a post with chart.js",description:"this is what included chart.js code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/chartjs/"}},{id:"post-a-post-with-tikzjax",title:"a post with TikZJax",description:"this is what included TikZ code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/tikzjax/"}},{id:"post-a-post-with-bibliography",title:"a post with bibliography",description:"an example of a blog post with bibliography",section:"Posts",handler:()=>{window.location.href="/blog/2023/post-bibliography/"}},{id:"post-a-post-with-jupyter-notebook",title:"a post with jupyter notebook",description:"an example of a blog post with jupyter notebook",section:"Posts",handler:()=>{window.location.href="/blog/2023/jupyter-notebook/"}},{id:"post-a-post-with-custom-blockquotes",title:"a post with custom blockquotes",description:"an example of a blog post with custom blockquotes",section:"Posts",handler:()=>{window.location.href="/blog/2023/custom-blockquotes/"}},{id:"post-a-post-with-table-of-contents-on-a-sidebar",title:"a post with table of contents on a sidebar",description:"an example of a blog post with table of contents on a sidebar",section:"Posts",handler:()=>{window.location.href="/blog/2023/sidebar-table-of-contents/"}},{id:"post-a-post-with-audios",title:"a post with audios",description:"this is what included audios could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/audios/"}},{id:"post-a-post-with-videos",title:"a post with videos",description:"this is what included videos could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/videos/"}},{id:"post-displaying-beautiful-tables-with-bootstrap-tables",title:"displaying beautiful tables with Bootstrap Tables",description:"an example of how to use Bootstrap Tables",section:"Posts",handler:()=>{window.location.href="/blog/2023/tables/"}},{id:"post-a-post-with-table-of-contents",title:"a post with table of contents",description:"an example of a blog post with table of contents",section:"Posts",handler:()=>{window.location.href="/blog/2023/table-of-contents/"}},{id:"post-a-post-with-giscus-comments",title:"a post with giscus comments",description:"an example of a blog post with giscus comments",section:"Posts",handler:()=>{window.location.href="/blog/2022/giscus-comments/"}},{id:"post-a-post-with-redirect",title:"a post with redirect",description:"you can also redirect to assets like pdf",section:"Posts",handler:()=>{window.location.href="/assets/pdf/example_pdf.pdf"}},{id:"post-a-post-with-diagrams",title:"a post with diagrams",description:"an example of a blog post with diagrams",section:"Posts",handler:()=>{window.location.href="/blog/2021/diagrams/"}},{id:"post-a-distill-style-blog-post",title:"a distill-style blog post",description:"an example of a distill-style blog post and main elements",section:"Posts",handler:()=>{window.location.href="/blog/2021/distill/"}},{id:"post-doxing-as-audience-vigilantism-against-hate-speech",title:"Doxing as Audience Vigilantism against Hate Speech",description:"A new book chapter on doxing.",section:"Posts",handler:()=>{window.location.href="/blog/2020/doxing_vigilantism/"}},{id:"post-a-post-with-twitter",title:"a post with twitter",description:"an example of a blog post with twitter",section:"Posts",handler:()=>{window.location.href="/blog/2020/twitter/"}},{id:"post-cyberwar-and-mediation-theory-with-nolen-gertz-and-peter-paul-verbeek",title:"Cyberwar and Mediation Theory (with Nolen Gertz and Peter-Paul Verbeek)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2019/cyberwar-and-mediation-theory/"}},{id:"post-the-satori-project",title:"The SATORI Project",description:"My work in a EU research project on responsible innovation.",section:"Posts",handler:()=>{window.location.href="/blog/2018/satori/"}},{id:"post-personal-information-identification-information-and-identity-knowledge",title:"Personal Information, Identification Information, and Identity Knowledge",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2018/identity_knowledge/"}},{id:"post-doxing-a-conceptual-analysis",title:"Doxing: A Conceptual Analysis",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2016/doxing/"}},{id:"post-a-post-with-disqus-comments",title:"a post with disqus comments",description:"an example of a blog post with disqus comments",section:"Posts",handler:()=>{window.location.href="/blog/2015/disqus-comments/"}},{id:"post-a-post-with-math",title:"a post with math",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/blog/2015/math/"}},{id:"post-a-post-with-code",title:"a post with code",description:"an example of a blog post with some code",section:"Posts",handler:()=>{window.location.href="/blog/2015/code/"}},{id:"post-a-post-with-images",title:"a post with images",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2015/images/"}},{id:"post-a-post-with-formatting-and-links",title:"a post with formatting and links",description:"march & april, looking forward to summer",section:"Posts",handler:()=>{window.location.href="/blog/2015/formatting-and-links/"}},{id:"post-towards-a-just-and-fair-internet-applying-rawls-39-principles-of-justice-to-internet-regulation",title:"Towards a Just and Fair Internet: Applying Rawls' Principles of Justice to Internet...",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2015/rawls_internet/"}},{id:"post-the-social-goods-of-information-networks-complex-equality-and-wu-39-s-separation-principles",title:"The Social Goods of Information Networks: Complex Equality and Wu's Separation Principles",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2014/social_goods/"}},{id:"post-pre-owned-games",title:"Pre-Owned Games",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2013/pre-owned_games/"}},{id:"post-making-ict-careers-accessible-the-value-of-certification",title:"Making ICT Careers Accessible: The Value of Certification",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2012/certification/"}},{id:"post-a-beneficial-monopoly-jeremy-bentham-on-monopolies-and-patents",title:"A Beneficial Monopoly: Jeremy Bentham on Monopolies and Patents",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2009/bentham_monopoly/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"projects-the-ethics-of-software-ownership",title:"The Ethics of Software Ownership",description:"Examining the ethical justifications for property rights over software",section:"Projects",handler:()=>{window.location.href="/projects/computer_software/"}},{id:"projects-doxing",title:"Doxing",description:"Examining the ethics of doxing",section:"Projects",handler:()=>{window.location.href="/projects/internet_doxing/"}},{id:"projects-distributive-justice-and-the-internet",title:"Distributive Justice and the Internet",description:"Applying theories of distributive justice to the Internet",section:"Projects",handler:()=>{window.location.href="/projects/internet_justice/"}},{id:"projects-responsible-research-automation",title:"Responsible Research Automation",description:"Examining researchers' views on automating science",section:"Projects",handler:()=>{window.location.href="/projects/ri_automation/"}},{id:"projects-trust-in-machine-learning-and-law-enforcement",title:"Trust in Machine Learning and Law Enforcement",description:"Investigating how to foster in ML by criminal investigators",section:"Projects",handler:()=>{window.location.href="/projects/ri_law/"}},{id:"projects-responsible-ai",title:"Responsible AI",description:"Investigating how AI ethical principles are used in practice",section:"Projects",handler:()=>{window.location.href="/projects/ri_rai/"}},{id:"projects-satori",title:"SATORI",description:"Stakeholders Acting Together On the ethical impact assessment of Research and Innovation",section:"Projects",handler:()=>{window.location.href="/projects/ri_satori/"}},{id:"projects-ethical-responsibility-for-ai-designed-surgical-robots",title:"Ethical Responsibility for AI-Designed Surgical Robots",description:"Examining ethical responsibility for AI-designed tools for surgical robots",section:"Projects",handler:()=>{window.location.href="/projects/ri_surgical/"}},{id:"socials-orcid",title:"ORCID",section:"Socials",handler:()=>{window.open("https://orcid.org/0000-0003-2448-871X","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=HnOi6FQAAAAJ","_blank")}},{id:"socials-ieee-xplore",title:"IEEE Xplore",section:"Socials",handler:()=>{window.open("https://ieeexplore.ieee.org/author/37089426068/","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/david-douglas-249289bb","_blank")}},{id:"socials-work",title:"Work",section:"Socials",handler:()=>{window.open("https://people.csiro.au/D/D/david-douglas","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>