<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://dmdouglas.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://dmdouglas.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-08-25T09:41:29+00:00</updated><id>https://dmdouglas.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">New Paper on Ethical Risk for AI</title><link href="https://dmdouglas.github.io/blog/2024/ethical-risk-for-ai/" rel="alternate" type="text/html" title="New Paper on Ethical Risk for AI"/><published>2024-08-12T09:58:00+00:00</published><updated>2024-08-12T09:58:00+00:00</updated><id>https://dmdouglas.github.io/blog/2024/ethical-risk-for-ai</id><content type="html" xml:base="https://dmdouglas.github.io/blog/2024/ethical-risk-for-ai/"><![CDATA[<p>A new paper that builds on the insights we gained from my postdoctoral research on responsiblity and surgical robotics has been published. In <a class="citation" href="#douglas2024ethical">(Douglas et al., 2024)</a>, my co-authors (Justine Lacey and David Howard) and I present an account of ethical risk for AI. It appears in the journal <em>AI &amp; Ethics</em> and is open access.</p> <p>I presented a earlier version of this paper at the 2023 Forum on Philosophy, Engineering and Technology held at TUDelft in the Netherlands in April 2023.</p>]]></content><author><name></name></author><category term="papers"/><category term="artificial-intelligence"/><category term="ethics"/><category term="risk"/><category term="responsibility"/><summary type="html"><![CDATA[A new paper that builds on the insights we gained from my postdoctoral research on responsiblity and surgical robotics has been published. In (Douglas et al., 2024), my co-authors (Justine Lacey and David Howard) and I present an account of ethical risk for AI. It appears in the journal AI &amp; Ethics and is open access.]]></summary></entry><entry><title type="html">New Paper on Justice in Energy Transformations</title><link href="https://dmdouglas.github.io/blog/2024/just-trade-offs/" rel="alternate" type="text/html" title="New Paper on Justice in Energy Transformations"/><published>2024-04-09T09:58:00+00:00</published><updated>2024-04-09T09:58:00+00:00</updated><id>https://dmdouglas.github.io/blog/2024/just-trade-offs</id><content type="html" xml:base="https://dmdouglas.github.io/blog/2024/just-trade-offs/"><![CDATA[<p>I’m a co-author with some of my CSIRO colleagues on energy justice. In <a href="https://www.sciencedirect.com/science/article/pii/S0195925524000933">“Just Trade-Offs in a Net-Zero Transition and Social Impact Assessment”</a> <a class="citation" href="#malakar2024just">(Malakar et al., 2024)</a>, we explain how Rawls’ theory of distributive justice may be used as part of a social impact assessment for introducing new energy technologies. It’s published in the journal <em>Environmental Impact Assessment Review</em>, and the paper is open access.</p>]]></content><author><name></name></author><category term="papers"/><category term="energy-justice"/><category term="net-zero"/><category term="Rawls"/><category term="justice-as-fairness"/><category term="distributive-justice"/><summary type="html"><![CDATA[I’m a co-author with some of my CSIRO colleagues on energy justice. In “Just Trade-Offs in a Net-Zero Transition and Social Impact Assessment” (Malakar et al., 2024), we explain how Rawls’ theory of distributive justice may be used as part of a social impact assessment for introducing new energy technologies. It’s published in the journal Environmental Impact Assessment Review, and the paper is open access.]]></summary></entry><entry><title type="html">Cited in ‘The Conversation’ Article</title><link href="https://dmdouglas.github.io/blog/2024/cited_conversation/" rel="alternate" type="text/html" title="Cited in ‘The Conversation’ Article"/><published>2024-02-20T10:58:00+00:00</published><updated>2024-02-20T10:58:00+00:00</updated><id>https://dmdouglas.github.io/blog/2024/cited_conversation</id><content type="html" xml:base="https://dmdouglas.github.io/blog/2024/cited_conversation/"><![CDATA[<p>My paper on doxing (missing reference) is cited in <a href="https://experts.griffith.edu.au/8299-hugh-breakey">Dr Hugh Breakey’s</a> recent article in <em>The Conversation</em>: <a href="https://theconversation.com/doxing-or-in-the-public-interest-free-speech-cancelling-and-the-ethics-of-the-jewish-creatives-whatsapp-group-leak-223323">‘Doxing or in the public interest? Free speech, “cancelling” and the ethics of the Jewish creatives’ WhatsApp group leak’</a>.</p>]]></content><author><name></name></author><category term="papers"/><category term="doxing"/><category term="vigilantism"/><category term="free-speech"/><summary type="html"><![CDATA[My paper on doxing (missing reference) is cited in Dr Hugh Breakey’s recent article in The Conversation: ‘Doxing or in the public interest? Free speech, “cancelling” and the ethics of the Jewish creatives’ WhatsApp group leak’.]]></summary></entry><entry><title type="html">Doxing as Audience Vigilantism against Hate Speech</title><link href="https://dmdouglas.github.io/blog/2020/doxing_vigilantism/" rel="alternate" type="text/html" title="Doxing as Audience Vigilantism against Hate Speech"/><published>2020-10-01T08:12:35+00:00</published><updated>2020-10-01T08:12:35+00:00</updated><id>https://dmdouglas.github.io/blog/2020/doxing_vigilantism</id><content type="html" xml:base="https://dmdouglas.github.io/blog/2020/doxing_vigilantism/"><![CDATA[<p>Doxing is the public release of personally identifiable information, and may be used as a tool for activism by removing the anonymity of individuals whose actions or stated beliefs harm others or undermine social cohesion. In this chapter I describe how doxing that deanomynises proponents of hate speech is a form of audience vigilantism. I argue that it is a defensible means of combating hate speech if it has the purpose of beginning a process of deradicalizing the identified individuals through reintegrative shaming. Such doxing must be motivated by a legitimate social need (in that they can be justified using premises and evidence acceptable to all in society), and must remain within socially tolerable bounds (in that it does not lead to physical harm, it is not indiscriminate, and is in response to injustices that are in principle recognisable to those who are not affected by it). I refer to several instances of doxing relating to proponents of hate speech to illustrate my argument and to demonstrate the importance of the legitimate social need and socially tolerable bounds criteria.</p> <p>This chapter appears in the book <em>Introducing Vigilant Audiences</em>, edited by Daniel Trottier, Rashid Gabdulhakov, and Qian Huang, and published by Open Book Publishers in 2020. The Open Access PDF of the book is available from the publisher’s website: <a href="https://www.openbookpublishers.com/product/1151">Introducing Vigilant Audiences - Open Book Publishers</a>.</p>]]></content><author><name></name></author><category term="papers"/><category term="doxing"/><category term="vigilantism"/><category term="hate-speech"/><summary type="html"><![CDATA[A new book chapter on doxing.]]></summary></entry><entry><title type="html">Cyberwar and Mediation Theory (with Nolen Gertz and Peter-Paul Verbeek)</title><link href="https://dmdouglas.github.io/blog/2019/cyberwar-and-mediation-theory/" rel="alternate" type="text/html" title="Cyberwar and Mediation Theory (with Nolen Gertz and Peter-Paul Verbeek)"/><published>2019-08-14T08:12:35+00:00</published><updated>2019-08-14T08:12:35+00:00</updated><id>https://dmdouglas.github.io/blog/2019/cyberwar-and-mediation-theory</id><content type="html" xml:base="https://dmdouglas.github.io/blog/2019/cyberwar-and-mediation-theory/"><![CDATA[<p>Cyberwar (military operations conducted via computer networks) is often downplayed compared to traditional military operations as they are largely invisible to outside observers, difficult to convincingly attribute to a particular source and rarely cause physical damage or obvious harm. We use mediation theory to argue that cyberwar operations cause harm by undermining trust in computerised devices and networks and by disrupting the transparency of our usage of information technology in our daily lives. Cyberwar operations militarise and weaponise the civilian space of the Internet by co-opting and targeting civilian infrastructure and property. These operations (and the possibility of such operations occurring) fundamentally change users’ Internet experience by fostering fear and paranoia about otherwise unnoticed and transparent aspects of their lives, similarly to how biological and chemical weapons create fear and paranoia about breathing, eating, and physical exposure to the world. We argue that the phenomenological aspects of cyberwar operations offer a compelling justification for prohibiting cyberwar in the same manner in which biological and chemical warfare are prohibited.</p> <p>This paper was co-written with Nolen Gertz and Peter-Paul Verbeek. It was published in volume 2, issue 2 of the journal <a href="https://delphi.lexxion.eu/article/DELPHI/2019/2/5"><em>Delphi - Interdisciplinary Review of Emerging Technologies</em></a>.</p>]]></content><author><name></name></author><category term="papers"/><category term="cyberwar"/><category term="meditation-theory"/><summary type="html"><![CDATA[Cyberwar (military operations conducted via computer networks) is often downplayed compared to traditional military operations as they are largely invisible to outside observers, difficult to convincingly attribute to a particular source and rarely cause physical damage or obvious harm. We use mediation theory to argue that cyberwar operations cause harm by undermining trust in computerised devices and networks and by disrupting the transparency of our usage of information technology in our daily lives. Cyberwar operations militarise and weaponise the civilian space of the Internet by co-opting and targeting civilian infrastructure and property. These operations (and the possibility of such operations occurring) fundamentally change users’ Internet experience by fostering fear and paranoia about otherwise unnoticed and transparent aspects of their lives, similarly to how biological and chemical weapons create fear and paranoia about breathing, eating, and physical exposure to the world. We argue that the phenomenological aspects of cyberwar operations offer a compelling justification for prohibiting cyberwar in the same manner in which biological and chemical warfare are prohibited.]]></summary></entry><entry><title type="html">The SATORI Project</title><link href="https://dmdouglas.github.io/blog/2018/satori/" rel="alternate" type="text/html" title="The SATORI Project"/><published>2018-05-07T08:12:35+00:00</published><updated>2018-05-07T08:12:35+00:00</updated><id>https://dmdouglas.github.io/blog/2018/satori</id><content type="html" xml:base="https://dmdouglas.github.io/blog/2018/satori/"><![CDATA[<p>SATORI (Stakeholders Acting Together On the ethical impact assessment of Research and Innovation) was a four-year EU project to develop a common European framework for the ethical assessment of research and innovation activity. I contributed to the project during my time with the University of Twente in 2015 and 2016.</p> <p>Further details about the project and the guidelines it developed are available at the <a href="http://satoriproject.eu/">SATORI website</a>.</p> <p>The specific project reports that I contributed to and their authors/compilers are listed below in alphabetical order.</p> <p><a href="http://satoriproject.eu/media/D4.1_Proposal_Ethics_Assessment_Framework.pdf">A Reasoned Proposal for Shared Approaches to Ethics Assessment in the European Context</a>.</p> <p>Compiled by Philip Jensen, Wessel Reijers, David Douglas, Faridun Sattarov, Agata Gurzawska, Alexandra Kapeller, Philip Brey (University of Twente); Rok Benčin (Scientific Research Centre of the Slovenian Academy of Sciences and Arts); Zuzanna Warso (Helsinki Foundation for Human Rights); Robert Braun (Institute for Advanced Studies, Vienna).</p> <p><a href="http://satoriproject.eu/media/4.b-Country-report-China.pdf">Ethics Assessment in Different Countries: China</a>.</p> <p>Written by Xin Ming, David Douglas, Agata Gurzawska, Philip Brey (University of Twente).</p> <p><a href="http://satoriproject.eu/media/2.c-Medical-Life-sciences.pdf">Ethics Assessment in Different Fields: Medical and Life Sciences</a>.</p> <p>Written by Karin van Leersum, David Douglas (University of Twente).</p> <p><a href="http://satoriproject.eu/media/D1.1_Ethical-assessment-of-RI_a-comparative-analysis.pdf">Ethical Assessment of Research and Innovation: A Comparative Analysis of Practices and Institutions in the EU and Selected Other Countries</a>.</p> <p>Compiled by Clare Shelley-Egan (Trilateral Research &amp; Consulting); Philip Brey (University of Twente); Rowena Rodrigues (Trilateral Research &amp; Consulting), David Douglas, Agata Gurzawska (University of Twente); Lise Bitsch (Danish Board of Technology Foundation); David Wright, Kush Wadhwa (Trilateral Research &amp; Consulting).</p> <p><a href="http://satoriproject.eu/media/D4.1_Annex_5_Universities.pdf">Models for Ethics Assessment and Guidance in Higher Education</a>.</p> <p>Written by Philip Brey, David Douglas, Alexandra Kapeller (University of Twente); Rok Benčin (Scientific Research Centre of the Slovenian Academy of Sciences and Arts); Daniela Ovadia (EUSJA); Doris Wolfslehner (ABC).</p> <p><a href="http://satoriproject.eu/media/D4.2_Outline_of_an_Ethics_Assessment_Framework.pdf">Outline of an Ethics Assessment Framework</a>.</p> <p>Compiled by Philip Jansen, Faridun Sattarov, David Douglas, Wessel Reijers, Agata Gurzawska, Alexandra Kapeller, Philip Brey (University of Twente); Ingrid Callies (UNESCO); Rok Benčin (Scientific Research Centre of the Slovenian Academy of Sciences and Arts); Zuzanna Warso (Helsinki Foundation for Human Rights).</p> <p><a href="http://satoriproject.eu/media/1.h-Ethics-and-Risk1.pdf">Principles and Approaches in Ethics Assessment: Ethics and Risk</a>.</p> <p>Written by Raija Koivisto (Technical Research Centre of Finland (VTT)); David Douglas (University of Twente).</p> <p><a href="http://satoriproject.eu/media/D4.3_SATORI_Roadmap.pdf">Roadmap towards Adoption of a Fully Developed Ethics Assessment Framework</a>.</p> <p>Written by Anna Leinonen, Raija Koivisto, Anu Tuominen (Technical Research Centre of Finland (VTT)); David Douglas, Agata Gurzawska, Philip Jensen, Alexander Kapeller, Philip Brey (University of Twente).</p>]]></content><author><name></name></author><category term="research"/><category term="SATORI"/><category term="responsible-innovation"/><category term="RRI"/><summary type="html"><![CDATA[My work in a EU research project on responsible innovation.]]></summary></entry><entry><title type="html">Personal Information, Identification Information, and Identity Knowledge</title><link href="https://dmdouglas.github.io/blog/2018/identity_knowledge/" rel="alternate" type="text/html" title="Personal Information, Identification Information, and Identity Knowledge"/><published>2018-03-01T08:12:35+00:00</published><updated>2018-03-01T08:12:35+00:00</updated><id>https://dmdouglas.github.io/blog/2018/identity_knowledge</id><content type="html" xml:base="https://dmdouglas.github.io/blog/2018/identity_knowledge/"><![CDATA[<p>This commentary responds to the primary article by Aste Corbridge in the <em>UniSA Student Law Review</em> (2017/2018) entitled ‘Responding to Doxing in Australia: Towards a Right to Informational Self-Determination?’. It discusses the way that concepts of ‘personal information’ and ‘identification information’ from the Privacy Act 1988 (Cth) correspond with the seven crucial types of identity knowledge identified by Gary T. Marx and argues that these statutory definitions should be expanded to offer better protection to victims of doxing in Australia.</p> <p>This paper was published in the 2017/2018 edition of the <a href="https://www.ojs.unisa.edu.au/index.php/uslr/issue/view/182"><em>UniSA Student Law Review</em></a>.</p>]]></content><author><name></name></author><category term="papers"/><category term="australian-law"/><category term="privacy"/><category term="doxing"/><summary type="html"><![CDATA[This commentary responds to the primary article by Aste Corbridge in the UniSA Student Law Review (2017/2018) entitled ‘Responding to Doxing in Australia: Towards a Right to Informational Self-Determination?’. It discusses the way that concepts of ‘personal information’ and ‘identification information’ from the Privacy Act 1988 (Cth) correspond with the seven crucial types of identity knowledge identified by Gary T. Marx and argues that these statutory definitions should be expanded to offer better protection to victims of doxing in Australia.]]></summary></entry><entry><title type="html">Doxing: A Conceptual Analysis</title><link href="https://dmdouglas.github.io/blog/2016/doxing/" rel="alternate" type="text/html" title="Doxing: A Conceptual Analysis"/><published>2016-06-01T08:12:35+00:00</published><updated>2016-06-01T08:12:35+00:00</updated><id>https://dmdouglas.github.io/blog/2016/doxing</id><content type="html" xml:base="https://dmdouglas.github.io/blog/2016/doxing/"><![CDATA[<p>Doxing is the intentional public release onto the Internet of personal information about an individual by a third party, often with the intent to humiliate, threaten, intimidate, or punish the identified individual. In this paper I present a conceptual analysis of the practice of doxing and how it differs from other forms of privacy violation. I distinguish between three types of doxing: deanonymizing doxing, where personal information establishing the identity of a formerly anonymous individual is released; targeting doxing, that discloses personal information that reveals specific details of an individual’s circumstances that are usually private, obscure, or obfuscated; and delegitimizing doxing, which reveals intimate personal information that damages the credibility of that individual. I also describe how doxing differs from blackmail and defamation. I argue that doxing may be justified in cases where it reveals wrongdoing (such as deception), but only if the information released is necessary to reveal that such wrongdoing has occurred and if it is in the public interest to reveal such wrongdoing. Revealing additional information, such as that which allows an individual to be targeted for harassment and intimidation, is unjustified. I illustrate my discussion with the examples of the alleged identification of the creator of Bitcoin, Satoshi Nakamoto, by Newsweek magazine, the identification of the notorious Reddit user Violentacrez by the blog Gawker, and the harassment of game developer Zoe Quinn in the ‘GamerGate’ Internet campaign.</p> <p>This paper was published as open access as <a class="citation" href="#douglas_doxing_2016">(Douglas, 2016)</a>.</p>]]></content><author><name></name></author><category term="papers"/><category term="doxing"/><summary type="html"><![CDATA[Doxing is the intentional public release onto the Internet of personal information about an individual by a third party, often with the intent to humiliate, threaten, intimidate, or punish the identified individual. In this paper I present a conceptual analysis of the practice of doxing and how it differs from other forms of privacy violation. I distinguish between three types of doxing: deanonymizing doxing, where personal information establishing the identity of a formerly anonymous individual is released; targeting doxing, that discloses personal information that reveals specific details of an individual’s circumstances that are usually private, obscure, or obfuscated; and delegitimizing doxing, which reveals intimate personal information that damages the credibility of that individual. I also describe how doxing differs from blackmail and defamation. I argue that doxing may be justified in cases where it reveals wrongdoing (such as deception), but only if the information released is necessary to reveal that such wrongdoing has occurred and if it is in the public interest to reveal such wrongdoing. Revealing additional information, such as that which allows an individual to be targeted for harassment and intimidation, is unjustified. I illustrate my discussion with the examples of the alleged identification of the creator of Bitcoin, Satoshi Nakamoto, by Newsweek magazine, the identification of the notorious Reddit user Violentacrez by the blog Gawker, and the harassment of game developer Zoe Quinn in the ‘GamerGate’ Internet campaign.]]></summary></entry><entry><title type="html">Towards a Just and Fair Internet: Applying Rawls’ Principles of Justice to Internet Regulation</title><link href="https://dmdouglas.github.io/blog/2015/rawls_internet/" rel="alternate" type="text/html" title="Towards a Just and Fair Internet: Applying Rawls’ Principles of Justice to Internet Regulation"/><published>2015-03-01T08:12:35+00:00</published><updated>2015-03-01T08:12:35+00:00</updated><id>https://dmdouglas.github.io/blog/2015/rawls_internet</id><content type="html" xml:base="https://dmdouglas.github.io/blog/2015/rawls_internet/"><![CDATA[<p>I suggest that the social justice issues raised by Internet regulation be exposed and examined by using a methodology adapted from that described by John Rawls in ‘A Theory of Justice’. Rawls’ theory uses the hypothetical scenario of people deliberating about the justice of social institutions from the ‘original position’ as a method of removing bias in decision-making about justice. The original position imposes a ‘veil of ignorance’ that hides the particular circumstances of individuals from them so that they will not be influenced by self-interest. I adapt Rawls’ methodology by introducing an abstract description of information technology to those deliberating about justice from within the original position. This abstract description focuses on information devices that users can use to access information (and which may record information about them as well) and information networks that information devices use to communicate. The abstractness of this description prevents the particular characteristics of the Internet and the computing devices in use from influencing the decisions about the just use and regulation of information technology and networks. From this abstract position, the principles of justice that the participants accept for the rest of society will also apply to the computing devices people use to communicate, and to Internet regulation.</p> <p>This paper was published as open access as <a class="citation" href="#douglas_towards_2015">(Douglas, 2015)</a>.</p>]]></content><author><name></name></author><category term="papers"/><category term="Rawls"/><category term="internet"/><category term="regulation"/><category term="distributive-justice"/><summary type="html"><![CDATA[I suggest that the social justice issues raised by Internet regulation be exposed and examined by using a methodology adapted from that described by John Rawls in ‘A Theory of Justice’. Rawls’ theory uses the hypothetical scenario of people deliberating about the justice of social institutions from the ‘original position’ as a method of removing bias in decision-making about justice. The original position imposes a ‘veil of ignorance’ that hides the particular circumstances of individuals from them so that they will not be influenced by self-interest. I adapt Rawls’ methodology by introducing an abstract description of information technology to those deliberating about justice from within the original position. This abstract description focuses on information devices that users can use to access information (and which may record information about them as well) and information networks that information devices use to communicate. The abstractness of this description prevents the particular characteristics of the Internet and the computing devices in use from influencing the decisions about the just use and regulation of information technology and networks. From this abstract position, the principles of justice that the participants accept for the rest of society will also apply to the computing devices people use to communicate, and to Internet regulation.]]></summary></entry><entry><title type="html">The Social Goods of Information Networks: Complex Equality and Wu’s Separation Principles</title><link href="https://dmdouglas.github.io/blog/2014/social_goods/" rel="alternate" type="text/html" title="The Social Goods of Information Networks: Complex Equality and Wu’s Separation Principles"/><published>2014-09-01T08:12:35+00:00</published><updated>2014-09-01T08:12:35+00:00</updated><id>https://dmdouglas.github.io/blog/2014/social_goods</id><content type="html" xml:base="https://dmdouglas.github.io/blog/2014/social_goods/"><![CDATA[<p>In his book <em>The Master Switch: The Rise and Fall of Information Empires</em>, Tim Wu proposes a ‘Separation Principle’ that the control of communication infrastructure should be separated from control over the information transmitted across it. I suggest that the Separation Principle can be further justified by appealing to Michael Walzer’s concept of complex equality. In this analysis, the integrated control of communication infrastructure and control over who can use it is unjust as the influence of the infrastructure sphere is influencing the sphere of expression. This gives a further theoretical justification for Wu’s Separation Principle and for resisting the monopolisation of information networks.</p> <p>This paper was published in the <a href="http://firstmonday.org/ojs/index.php/fm/article/view/4652/4117">September 2014 edition of <em>First Monday</em></a>.</p>]]></content><author><name></name></author><category term="papers"/><category term="net-neutrality"/><category term="complex-equality"/><category term="distributive-justice"/><category term="social-goods"/><summary type="html"><![CDATA[In his book The Master Switch: The Rise and Fall of Information Empires, Tim Wu proposes a ‘Separation Principle’ that the control of communication infrastructure should be separated from control over the information transmitted across it. I suggest that the Separation Principle can be further justified by appealing to Michael Walzer’s concept of complex equality. In this analysis, the integrated control of communication infrastructure and control over who can use it is unjust as the influence of the infrastructure sphere is influencing the sphere of expression. This gives a further theoretical justification for Wu’s Separation Principle and for resisting the monopolisation of information networks.]]></summary></entry></feed>